# Pool of Twitter app developer credentials to use to crawl (each pool is specified by four properties ending with the same number: integer from 1 to 150)
# Credentials of the pool are used in a round robin way.
# Go to: https://apps.twitter.com/ in order to create your credentials
#    - for streaming crawlers it is needed to specify only one pool of credentials
#    - for rest crawler, more credential pools are specified, faster is the crawling process
# IMPORTANT: it is possible to specify up to 150 credentials
consumerKey_1=PUT_YOUR_CONSUMER_KEY_NUM_1
consumerSecret_1=PUT_YOUR_CONSUMER_SECRET_NUM_1
token_1=PUT_YOUR_TOKEN_NUM_1
tokenSecret_1=PUT_YOUR_TOKEN_SECRET_NUM_1

#consumerKey_2=PUT_YOUR_CONSUMER_KEY_NUM_2
#consumerSecret_2=PUT_YOUR_CONSUMER_SECRET_NUM_2
#token_2=PUT_YOUR_TOKEN_NUM_2
#tokenSecret_2=PUT_YOUR_TOKEN_SECRET_NUM_2

#consumerKey_3=PUT_YOUR_CONSUMER_KEY_NUM_3
#consumerSecret_3=PUT_YOUR_CONSUMER_SECRET_NUM_3
#token_3=PUT_YOUR_TOKEN_NUM_3
#tokenSecret_3=PUT_YOUR_TOKEN_SECRET_NUM_3

#consumerKey_4=PUT_YOUR_CONSUMER_KEY_NUM_4
#consumerSecret_4=PUT_YOUR_CONSUMER_SECRET_NUM_4
#token_4=PUT_YOUR_TOKEN_NUM_4
#tokenSecret_4=PUT_YOUR_TOKEN_SECRET_NUM_4

####################################################################################
# REST Cralwer of Twitter - by list of tweet IDs (tweetID)
# Class: org.backingdata.twitter.crawler.rest.TwitterRESTTweetIDlistCrawler
#   - Full path of the txt file to read tweet IDs from (one tweet ID per line)
tweetID.fullPathTweetIDs=./train_us_semeval18.ids
#   - Full path of the output folder to store crawling results 
tweetID.fullOutputDirPath=./data/
#   - Storage format: "json" to store one tweet per line as tweet JSON object or "tab" to store one tweet per line as TWEET_ID<TAB>TWEET_TEXT
#   IMPORTANT: to crawl SemEval 2018 tweets, leave this property equal to json
tweetID.outputFormat=json

